{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d392d022",
   "metadata": {},
   "source": [
    "## Install Hub, Coco API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcde982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "!pip install hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ebe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/activeloopai/Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0bef7",
   "metadata": {},
   "source": [
    "## Download and Unzip COCO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN ONCE\n",
    "!mkdir ./Datasets/coco\n",
    "!mkdir ./Datasets/coco/annotations\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/zips/train2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/zips/test2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/zips/unlabeled2017.zip\n",
    "    \n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "!wget -P ./Datasets/coco http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n",
    "\n",
    "!unzip -q ./Datasets/coco/train2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/val2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/test2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/unlabeled2017.zip -d ./Datasets/coco\n",
    "\n",
    "!unzip -q ./Datasets/coco/annotations_trainval2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/stuff_annotations_trainval2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/image_info_test2017.zip -d ./Datasets/coco\n",
    "!unzip -q ./Datasets/coco/image_info_unlabeled2017.zip -d ./Datasets/coco\n",
    "\n",
    "!unzip -q ./Datasets/coco/annotations/stuff_val2017_pixelmaps.zip -d ./Datasets/coco/annotations\n",
    "!unzip -q ./Datasets/coco/annotations/stuff_train2017_pixelmaps.zip -d ./Datasets/coco/annotations\n",
    "\n",
    "!rm -r ./Datasets/coco/train2017.zip\n",
    "!rm -r ./Datasets/coco/val2017.zip\n",
    "!rm -r ./Datasets/coco/test2017.zip\n",
    "!rm -r ./Datasets/coco/unlabeled2017.zip\n",
    "!rm -r ./Datasets/coco/stuff_annotations_trainval2017.zip\n",
    "!rm -r ./Datasets/coco/image_info_unlabeled2017.zip\n",
    "!rm -r ./Datasets/coco/image_info_test2017.zip\n",
    "!rm -r ./Datasets/coco/annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe42dbd",
   "metadata": {},
   "source": [
    "## Import Dataset To Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2515cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BUGGER_OFF=true\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/bin/activeloop\", line 5, in <module>\n",
      "    from hub.cli.commands import cli\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/__init__.py\", line 26, in <module>\n",
      "    from .api.dataset import dataset\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/api/dataset.py\", line 6, in <module>\n",
      "    from hub.auto.unstructured.image_classification import ImageClassification\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/auto/unstructured/image_classification.py\", line 14, in <module>\n",
      "    from hub.core.dataset import Dataset\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/dataset/__init__.py\", line 1, in <module>\n",
      "    from .dataset import Dataset\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/dataset/dataset.py\", line 17, in <module>\n",
      "    from hub.core.tensor import Tensor, create_tensor\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/tensor.py\", line 2, in <module>\n",
      "    from hub.core.chunk.base_chunk import InputSample\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/chunk/base_chunk.py\", line 14, in <module>\n",
      "    from hub.core.serialize import (\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/serialize.py\", line 2, in <module>\n",
      "    from hub.core.tiling.sample_tiles import SampleTiles  # type: ignore\n",
      "ModuleNotFoundError: No module named 'hub.core.tiling'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hub.core.tiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8a4d49b33c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'env'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BUGGER_OFF=true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activeloop reporting --off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"Dataset.num_samples\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m }\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/api/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaggle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstructured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHubBackendClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/auto/unstructured/image_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mTensorInvalidSampleShapeError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/dataset/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhub_cloud_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHubCloudDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_hub_cloud_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/dataset/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasetMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLRUCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS3Provider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit_node\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCommitNode\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtype\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_HTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTYPE_CONFIGURATIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_control\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit_diff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCommitDiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_chunk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/chunk/base_chunk.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_meta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSample\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from hub.core.serialize import (\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdeserialize_chunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minfer_chunk_num_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/hub/core/serialize.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBYTE_COMPRESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_compression_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_tiles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSampleTiles\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compression_ratio\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorInvalidSampleShapeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcasting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mintelligent_cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hub.core.tiling'"
     ]
    }
   ],
   "source": [
    "%env BUGGER_OFF=true\n",
    "!activeloop reporting --off\n",
    "import hub\n",
    "import numpy as np\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73f0e1",
   "metadata": {},
   "source": [
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./Datasets/coco'\n",
    "data_type='val' # Valid choices are 'train' and 'val'. Testing is a special case at the end of the notebook\n",
    "\n",
    "hub_path = './Datasets/coco_local_{}'.format(data_type) # 'hub://my_worksace/coco_{}'.format(data_type)\n",
    "\n",
    "limit = 1e10 # Limit the number of images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232920e",
   "metadata": {},
   "source": [
    "### Load Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file='{}/annotations/instances_{}2017.json'.format(data_dir,data_type)\n",
    "ann_file_kp = '{}/annotations/person_keypoints_{}2017.json'.format(data_dir,data_type)\n",
    "ann_file_stuff = '{}/annotations/stuff_{}2017.json'.format(data_dir,data_type)\n",
    "img_root='{}/{}2017/'.format(data_dir,data_type)\n",
    "\n",
    "coco = COCO(ann_file)\n",
    "coco_kp=COCO(ann_file_kp)\n",
    "coco_stuff=COCO(ann_file_stuff)\n",
    "\n",
    "category_info = coco.loadCats(coco.getCatIds())\n",
    "category_info_kp = coco_kp.loadCats(coco_kp.getCatIds())\n",
    "category_info_stuff = coco_stuff.loadCats(coco_stuff.getCatIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519ab48",
   "metadata": {},
   "source": [
    "### Create hub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3208ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to activeloop if using Activeloop Storage (hub://.....)\n",
    "!activeloop login -u 'username' -p 'password'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6718ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify dataset path\n",
    "ds = hub.empty(hub_path, overwrite = True) # Set overwrite = True if you need to start over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092dd2f",
   "metadata": {},
   "source": [
    "### Create lists for all the class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = [category['name'] for category in category_info]\n",
    "super_cat_names = list(set([category['supercategory'] for category in category_info]))\n",
    "cat_names_kp = [category['name'] for category in category_info_kp]\n",
    "super_cat_names_kp = list(set([category['supercategory'] for category in category_info_kp]))\n",
    "cat_names_stuff = [category['name'] for category in category_info_stuff]\n",
    "super_cat_names_stuff = list(set([category['supercategory'] for category in category_info_stuff]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee56d4",
   "metadata": {},
   "source": [
    "### Upload data to Hub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = sorted(coco.getImgIds()) # Image ids for uploading\n",
    "count = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with ds:\n",
    "    \n",
    "    ## ---- Create Tensors ----- ##\n",
    "    \n",
    "    #Primary Data\n",
    "    ds.create_tensor('images', htype = 'image', sample_compression = 'jpg')\n",
    "    ds.create_tensor('images_meta', htype = 'json')\n",
    "    ds.create_tensor('masks', htype = 'binary_mask', sample_compression = 'lz4')\n",
    "    ds.create_tensor('boxes', htype = 'bbox')\n",
    "    ds.create_tensor('categories', htype = 'class_label', class_names = cat_names)\n",
    "    ds.create_tensor('super_categories', htype = 'class_label', class_names = super_cat_names)\n",
    "    ds.create_tensor('areas', dtype = 'uint32')\n",
    "    ds.create_tensor('iscrowds', dtype = 'bool')\n",
    "    \n",
    "    #Pose\n",
    "    ds.create_group('pose')\n",
    "    ds.pose.create_tensor('categories', htype = 'class_label', class_names = cat_names_kp)\n",
    "    ds.pose.create_tensor('super_categories', htype = 'class_label', class_names = super_cat_names_kp)\n",
    "    ds.pose.create_tensor('boxes', htype = 'bbox')\n",
    "    ds.pose.create_tensor('keypoints', htype = 'keypoints_coco', dtype = 'int32')\n",
    "    ds.pose.create_tensor('masks', htype = 'binary_mask', sample_compression = 'lz4')\n",
    "    \n",
    "    #Stuff Segmentation\n",
    "    ds.create_group('stuff')\n",
    "    ds.stuff.create_tensor('masks', htype = 'binary_mask', sample_compression = 'lz4')\n",
    "    ds.stuff.create_tensor('boxes', htype = 'bbox')\n",
    "    ds.stuff.create_tensor('categories', htype = 'class_label', class_names = cat_names)\n",
    "    ds.stuff.create_tensor('super_categories', htype = 'class_label', class_names = super_cat_names)\n",
    "    ds.stuff.create_tensor('areas', dtype = 'uint32')\n",
    "    ds.stuff.create_tensor('iscrowds', dtype = 'bool')\n",
    "    \n",
    "    #Further updates to meta information\n",
    "    ds.categories.info.update(category_info = category_info, notes = 'Numeric labels for categories represent the position of the class in the ds.categories.info.class_names list, and not the COCO category id.')\n",
    "    ds.super_categories.info.update(category_info = category_info, notes = 'Numeric labels for super_categories represent the position of the class in the ds.super_categories.info.class_names list, and not the COCO category id.')\n",
    "    ds.masks.info.update(notes = 'All segmentation polygons and RLEs were converted to stacked binary masks')\n",
    "    ds.pose.masks.info.update(category_info = category_info_kp, notes = 'All segmentation polygons and RLEs were converted to stacked binary masks')\n",
    "    ds.pose.keypoints.info.update(keypoints = [category['keypoints'] for category in category_info_kp][0], connections = [category['skeleton'] for category in category_info_kp][0])\n",
    "    ds.stuff.masks.info.update(category_info = category_info_stuff, notes = 'All segmentation polygons and RLEs were converted to stacked binary masks')\n",
    "    \n",
    "    ## ---- Iterate through each image and upload data ----- ##\n",
    "    for img_id in img_ids:\n",
    "        ann_ids = coco.getAnnIds(img_id)\n",
    "        ann_ids_kp = coco_kp.getAnnIds(img_id)\n",
    "        ann_ids_stuff = coco_stuff.getAnnIds(img_id)\n",
    "        \n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        anns_kp = coco_kp.loadAnns(ann_ids_kp)\n",
    "        anns_stuff = coco_stuff.loadAnns(ann_ids_stuff)\n",
    "        \n",
    "        img_coco = coco.loadImgs(img_id)[0]\n",
    "        img_fn = os.path.join(img_root, img_coco['file_name'])\n",
    "        img = Image.open(img_fn)\n",
    "        dims = img.size\n",
    "        \n",
    "        \n",
    "        #Iterate through annotations and parse each\n",
    "        \n",
    "        #First Create empty arrays for all annotations\n",
    "        masks = np.zeros((dims[1], dims[0], len(anns)))\n",
    "        boxes = np.zeros((len(anns),4))\n",
    "        categories = np.zeros((len(anns)))\n",
    "        supercats = np.zeros((len(anns)))\n",
    "        areas = np.zeros((len(anns)))\n",
    "        iscrowds = np.zeros((len(anns)))\n",
    "        supercats = np.zeros((len(anns)))\n",
    "        \n",
    "        #Then populate the arrays with the annotations data\n",
    "        for i, ann in enumerate(anns):\n",
    "            mask = coco.annToMask(ann) #Convert annotation to mask\n",
    "            masks[:,:,i] = mask\n",
    "            boxes[i,:] = ann['bbox']\n",
    "            \n",
    "            # Do a brute force search and make no assumptions between order of relationship of category ids\n",
    "            categories[i] = cat_names.index([category_info[i]['name'] for i in range(len(category_info)) if category_info[i]['id']==ann['category_id']][0])\n",
    "            supercats[i] = super_cat_names.index([category_info[i]['supercategory'] for i in range(len(category_info)) if category_info[i]['id']==ann['category_id']][0])\n",
    "            \n",
    "            areas[i] = ann['area']\n",
    "            iscrowds[i] = ann['iscrowd']            \n",
    "\n",
    "            if 'segmentation' not in ann:\n",
    "                print('--- No segmentation found in annotations. ---')\n",
    "                print('Annotation length: {}'.format(len(anns)))\n",
    "                print('--- image id: {} ---'.format(img_id))        \n",
    "        \n",
    "        #Iterate through keypoints and parse each\n",
    "    \n",
    "        categories_kp = np.zeros((len(anns_kp)))\n",
    "        supercats_kp = np.zeros((len(anns_kp)))\n",
    "        masks_kp = np.zeros((dims[1], dims[0], len(anns_kp)))\n",
    "        boxes_kp = np.zeros((len(anns_kp),4))\n",
    "        keypoints_kp = np.zeros((51,len(anns_kp)))\n",
    "\n",
    "        for j, ann_kp in enumerate(anns_kp):\n",
    "            categories_kp[j] = cat_names_kp.index([category_info_kp[i]['name'] for i in range(len(category_info_kp)) if category_info_kp[i]['id']==ann_kp['category_id']][0])\n",
    "            supercats_kp[j] = super_cat_names_kp.index([category_info_kp[i]['supercategory'] for i in range(len(category_info_kp)) if category_info_kp[i]['id']==ann_kp['category_id']][0])\n",
    "            mask_kp = coco.annToMask(ann_kp) #Convert annotation to mask\n",
    "            masks_kp[:,:,j] = mask_kp\n",
    "            boxes_kp[j,:] = ann_kp['bbox']\n",
    "            keypoints_kp[:,j] = np.array(ann_kp['keypoints'])\n",
    "\n",
    "            \n",
    "        #Iterate through stuff and parse each\n",
    "        \n",
    "        masks_stuff = np.zeros((dims[1], dims[0], len(anns_stuff)))\n",
    "        boxes_stuff = np.zeros((len(anns_stuff),4))\n",
    "        categories_stuff = np.zeros((len(anns_stuff)))\n",
    "        supercats_stuff = np.zeros((len(anns_stuff)))\n",
    "        areas_stuff = np.zeros((len(anns_stuff)))\n",
    "        iscrowds_stuff = np.zeros((len(anns_stuff)))\n",
    "        supercats_stuff = np.zeros((len(anns_stuff)))\n",
    "        \n",
    "        for k, ann_stuff in enumerate(anns_stuff):\n",
    "            mask_stuff = coco.annToMask(ann_stuff) #Convert annotation to mask\n",
    "            masks_stuff[:,:,k] = mask_stuff\n",
    "            boxes_stuff[k,:] = ann['bbox']\n",
    "            \n",
    "            # Do a brute force search and make no assumptions between order of relationship of category ids\n",
    "            categories_stuff[k] = cat_names_stuff.index([category_info_stuff[i]['name'] for i in range(len(category_info_stuff)) if category_info_stuff[i]['id']==ann_stuff['category_id']][0])\n",
    "            supercats_stuff[k] = super_cat_names_stuff.index([category_info_stuff[i]['supercategory'] for i in range(len(category_info_stuff)) if category_info_stuff[i]['id']==ann_stuff['category_id']][0])\n",
    "            \n",
    "            areas_stuff[k] = ann_stuff['area']\n",
    "            iscrowds_stuff[k] = ann_stuff['iscrowd']            \n",
    "\n",
    "            if 'segmentation' not in ann_stuff:\n",
    "                print('--- No segmentation found in stuff annotations. ---')\n",
    "                print('Annotation length: {}'.format(len(anns)))\n",
    "                print('--- image id: {} ---'.format(img_id))        \n",
    "            \n",
    "            \n",
    "        #Append data to hub. Only do this after all annotations have been parsed.\n",
    "        try:\n",
    "            ds.images.append(hub.read(img_fn, verify = True))\n",
    "            ds.images_meta.append(img_coco)\n",
    "            ds.masks.append(masks.astype('bool'))\n",
    "            ds.boxes.append(boxes.astype('float32'))\n",
    "            ds.categories.append(categories.astype('uint32'))\n",
    "            ds.super_categories.append(supercats.astype('uint32'))\n",
    "            ds.areas.append(areas.astype('uint32'))\n",
    "            ds.iscrowds.append(iscrowds.astype('bool'))\n",
    "\n",
    "            ds.pose.categories.append(categories_kp.astype('uint32'))\n",
    "            ds.pose.super_categories.append(supercats_kp.astype('uint32'))\n",
    "            ds.pose.boxes.append(boxes_kp.astype('float32'))\n",
    "            ds.pose.masks.append(masks_kp.astype('bool'))\n",
    "            ds.pose.keypoints.append(keypoints_kp.astype('int32')) \n",
    "\n",
    "            ds.stuff.masks.append(masks_stuff.astype('bool'))\n",
    "            ds.stuff.boxes.append(boxes_stuff.astype('float32'))\n",
    "            ds.stuff.categories.append(categories_stuff.astype('uint32'))\n",
    "            ds.stuff.super_categories.append(supercats_stuff.astype('uint32'))\n",
    "            ds.stuff.areas.append(areas_stuff.astype('uint32'))\n",
    "            ds.stuff.iscrowds.append(iscrowds_stuff.astype('bool'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        if count%100==0:\n",
    "            print('Uploaded {} images'.format(count))\n",
    "\n",
    "        if count>=limit:\n",
    "            break\n",
    "            \n",
    "        count+=1   \n",
    "\n",
    "    print('Finished')\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Upload took {} seconds'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69470ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dac35eb5",
   "metadata": {},
   "source": [
    "## Special case - COCO Test dataset without annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba536c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./Datasets/coco'\n",
    "data_type='test'\n",
    "\n",
    "hub_path = './Datasets/coco_local_{}'.format(data_type) # 'hub://my_worksace/coco_{}'.format(data_type)\n",
    "\n",
    "limit = 1e10 # Limit the number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file='{}/annotations/image_info_{}2017.json'.format(data_dir,data_type) #There are no actual annotations, just images\n",
    "img_root='{}/{}2017/'.format(data_dir,data_type)\n",
    "\n",
    "coco = COCO(ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify dataset path\n",
    "ds = hub.empty(hub_path) # Set overwrite = True if you need to start over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = sorted(coco.getImgIds()) # Image ids for uploading\n",
    "count = 1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with ds:\n",
    "    \n",
    "    ## ---- Create Tensors ----- ##\n",
    "    \n",
    "    ds.create_tensor('images', htype = 'image', sample_compression = 'jpg')\n",
    "    ds.create_tensor('images_meta', htype = 'json')\n",
    "    \n",
    "    \n",
    "    ## ---- Iterate through each image and upload data ----- ##\n",
    "        \n",
    "    for img_id in img_ids:\n",
    "\n",
    "        img_coco = coco.loadImgs(img_id)[0]\n",
    "        img_fn = os.path.join(img_root, img_coco['file_name'])\n",
    "        img = Image.open(img_fn)\n",
    "        dims = img.size\n",
    "                \n",
    "        #Append data to hub\n",
    "        try:\n",
    "            ds.images.append(hub.read(img_fn, verify = True))\n",
    "            ds.images_meta.append(img_coco)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        if count%100==0:\n",
    "            print('Uploaded {} images'.format(count))\n",
    "\n",
    "        if count>=limit:\n",
    "            break\n",
    "            \n",
    "        count+=1   \n",
    "\n",
    "    print('Finished')\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print('Upload took {} seconds'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87c152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
