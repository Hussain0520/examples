{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30085b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hub\n",
    "import numpy as np\n",
    "import boto3\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a66c89",
   "metadata": {},
   "source": [
    "## Upload COCO-train with Bounding Boxes Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8c2b1",
   "metadata": {},
   "source": [
    "#### Coco will be uploaded using linked tensors, which means that instead of copying the image data to Hub format, the Hub dataset will store references to the S3 URLs where the images are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb422cd6",
   "metadata": {},
   "source": [
    "### Define the path to the bucket with the source data and create a new hub dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd73ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection to the source data\n",
    "dataset_bucket = 'non-hub-datasets'\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "         aws_access_key_id=os.environ.get('aws_access_key_id'), \n",
    "         aws_secret_access_key=os.environ.get('aws_secret_access_key'))\n",
    "\n",
    "s3_bucket = s3.Bucket(dataset_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdacd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations locally for easier processing\n",
    "ann_path = 'coco/annotations/instances_train2017.json'\n",
    "local_ann_path = 'anns_train.json'\n",
    "\n",
    "s3_bucket.download_file(ann_path, local_ann_path)\n",
    "coco = COCO(local_ann_path)\n",
    "\n",
    "category_info = coco.loadCats(coco.getCatIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hub dataset and connect it to managed credentials\n",
    "ds = hub.empty('hub://dl-corp/coco-train', token = 'Insert API Token')\n",
    "\n",
    "creds_name = \"my_s3_creds\"\n",
    "ds.add_creds_key(creds_name, managed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfb8b8",
   "metadata": {},
   "source": [
    "### Define the dataset tensors and create the parallel uploading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all the cetegories\n",
    "category_names = [category['name'] for category in category_info]\n",
    "\n",
    "# Image ids for uploading\n",
    "img_ids = sorted(coco.getImgIds())\n",
    "\n",
    "# Create tensors\n",
    "with ds:\n",
    "    ds.create_tensor('images', htype = 'link[image]')\n",
    "    ds.create_tensor('boxes', htype = 'bbox')\n",
    "    ds.create_tensor('categories', htype = 'class_label', class_names = category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f17442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel uploading function decorated with @hub.compute\n",
    "@hub.compute\n",
    "def coco_2_hub(img_id, sample_out, coco_api, bucket, creds_key):\n",
    "\n",
    "    anns = coco_api.loadAnns(coco_api.getAnnIds(img_id))\n",
    "    img_coco = coco_api.loadImgs(img_id)[0]\n",
    "            \n",
    "    # First Create empty arrays for all annotations\n",
    "    categories = np.zeros((len(anns)))\n",
    "    boxes = np.zeros((len(anns),4))\n",
    "    \n",
    "    # Then populate the arrays with the annotations data\n",
    "    for i, ann in enumerate(anns):\n",
    "        boxes[i,:] = ann['bbox']\n",
    "        categories[i] = category_names.index([category_info[i]['name'] for i in range(len(category_info)) if category_info[i]['id']==ann['category_id']][0])\n",
    "    \n",
    "    img_url = \"s3://{}/coco/train2017/{}\".format(bucket, img_coco['file_name'])\n",
    "\n",
    "    # Append data to the sample after all the annotations have been parsed\n",
    "    sample_out.append({\"images\": hub.link(img_url, creds_key=creds_key),\n",
    "                        \"boxes\": boxes.astype('float32'),\n",
    "                        \"categories\": categories.astype('uint32')})\n",
    "    \n",
    "    return sample_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dadf1cd",
   "metadata": {},
   "source": [
    "### Run the parallel uploading function and commit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the uplading function\n",
    "coco_2_hub(coco_api = coco, bucket = dataset_bucket, creds_key = creds_name).eval(img_ids, ds, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836bde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.commit('Uploaded the dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c18a7e5b6ff84ec8af70f0053f08fa65dad397e6ed6e820ac7403aeb2095bb6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
