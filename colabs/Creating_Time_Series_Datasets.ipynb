{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating Time-Series Datasets",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/activeloopai/examples/blob/main/colabs/Creating_Time_Series_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKU8kmSs65xv"
      },
      "source": [
        "# ***Creating Time-Series Datasets***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zK9b4yiMRzB"
      },
      "source": [
        "#### Hub is intuitive format for storing large time-series datasets and it offers compression for reducing storage costs. This tutorial demonstrates how to convert a time-series data to hub format and load the data for plotting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UseHLcoRIYz"
      },
      "source": [
        "## Install Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mOffq5RN-T"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip3 install hub\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wGo53ndMTCB"
      },
      "source": [
        "## Create the Hub Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52h9xKujOJFs"
      },
      "source": [
        "The first step is to download the small dataset below called *sensor data*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6m__biyt5I1"
      },
      "source": [
        "# Download dataset\n",
        "from IPython.display import clear_output\n",
        "!wget https://github.com/activeloopai/examples/raw/main/colabs/starting_data/sensor_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fNxNZIft5F-"
      },
      "source": [
        "# Unzip to './animals_od' folder\n",
        "!unzip -qq /content/sensor_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLh4uuIMuNwt"
      },
      "source": [
        "This is a subset of a [dataset available on kaggle](https://www.kaggle.com/malekzadeh/motionsense-dataset), and it contains the iPhone x,y,z acceleration for 24 users (subjects) under conditions of walking and jogging. The dataset has the folder structure below. `subjects_info.csv` contains metadata such as `height`, `weight`, etc. for each subject, and the `sub_n.csv` files contains the time-series acceleration data for the nth subject."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHyrqNgNuRO2"
      },
      "source": [
        "data_dir\n",
        "- subjects_into.csv\n",
        "- walk\n",
        "  - sub_1.csv\n",
        "  - sub_2.csv\n",
        "- jog\n",
        "  - sub_1.csv\n",
        "  - sub_2.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_iOi_9NuXAI"
      },
      "source": [
        "Now that you have the data, let's **create a Hub Dataset** in the `./sensor_data_hub` folder by running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZtpnpTOp-5"
      },
      "source": [
        "import hub\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ds = hub.empty('./sensor_data_hub') # Create the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNMOv3LPOyAd"
      },
      "source": [
        "Next, let's specify the folder path containing the existing dataset, load the subjects metadata to a Pandas DataFrame, and create a list of all of the time-series files that should be converted to hub format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCjN0EKwO1Pu"
      },
      "source": [
        "dataset_path= './sensor_data'\n",
        "subjects_info = pd.read_csv(os.path.join(dataset_path, 'subjects_info.csv'))\n",
        "fns_series = []\n",
        "for dirpath, dirnames, filenames in os.walk(os.path.join(dataset_path, 'motion_data')):\n",
        "    for filename in filenames:\n",
        "        fns_series .append(os.path.join(dirpath, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4CPD4nmO3_S"
      },
      "source": [
        "Next, let's create the tensors and add relevant metadata, such as the dataset source, the tensor units, and other information. We leverage `groups` to separate out the primary acceleration data from other user data such as the weight and height of the subjects.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRIDfYXNO7kg"
      },
      "source": [
        "with ds:\n",
        "    #Update dataset metadata\n",
        "    ds.info.update(source = 'https://www.kaggle.com/malekzadeh/motionsense-dataset', \n",
        "                   notes = 'This is a small subset of the data in the source link')\n",
        "\n",
        "    #Create tensors. Setting chunk_compression is optional and it defaults to None\n",
        "    ds.create_tensor('acceleration_x', chunk_compression = 'lz4') \n",
        "    ds.create_tensor('acceleration_y', chunk_compression = 'lz4')\n",
        "    \n",
        "    # Save the sampling rate as tensor metadata. Alternatively,\n",
        "    # you could also create a 'time' tensor.\n",
        "    ds.acceleration_x.info.update(sampling_rate_s = 0.1)\n",
        "    ds.acceleration_y.info.update(sampling_rate_s = 0.1)\n",
        "    \n",
        "    # Encode activity as text\n",
        "    ds.create_tensor('activity', htype = 'text')\n",
        "    \n",
        "    # Encode 'activity' as numeric labels and convert to text via class_names\n",
        "    # ds.create_tensor('activity', htype = 'class_label', class_names = ['xyz'])\n",
        "    \n",
        "    ds.create_group('subjects_info')\n",
        "    ds.subjects_info.create_tensor('age')\n",
        "    ds.subjects_info.create_tensor('weight')\n",
        "    ds.subjects_info.create_tensor('height')\n",
        "    \n",
        "    # Save the units of weight as tensor metadata\n",
        "    ds.subjects_info.weight.info.update(units = 'kg')\n",
        "    ds.subjects_info.height.info.update(units = 'cm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKvPUjxcUPvO"
      },
      "source": [
        "Finally, let's iterate through all the time-series data and populate the tensors in the Hub dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2F4TXd0UEtH"
      },
      "source": [
        "with ds:\n",
        "    # Iterate through the time series and append data\n",
        "    for fn in tqdm(fns_series):\n",
        "        \n",
        "        # Read the data in the time series\n",
        "        df_data = pd.read_csv(fn)\n",
        "        \n",
        "        # Parse the 'activity' from the file name\n",
        "        activity = os.path.basename(os.path.dirname(fn))\n",
        "        \n",
        "        # Parse the subject code from the filename  and pull the subject info from 'subjects_info'\n",
        "        subject_code = int(os.path.splitext(os.path.basename(fn))[0].split('_')[1])\n",
        "        subject_info = subjects_info[subjects_info['code']==subject_code]\n",
        "        \n",
        "        # Append data to tensors\n",
        "        ds.append({'activity': activity,\n",
        "                   'subjects_info/age': subject_info['age'].values,\n",
        "                   'subjects_info/weight': subject_info['weight'].values,\n",
        "                   'subjects_info/height': subject_info['height'].values,\n",
        "                   'acceleration_x': df_data['userAcceleration.x'].values,\n",
        "                   'acceleration_y': df_data['userAcceleration.y'].values\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCI61o-O9CV"
      },
      "source": [
        "##Inspect the Hub Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXkD-gLgO_7L"
      },
      "source": [
        "Let's check out the first sample from this dataset and plot the acceleration time-series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDFDJzQg6EsR"
      },
      "source": [
        "**It is noteworthy that the hub dataset takes 36% less memory than the original dataset due to lz4 chunk compression for  the acceleration tensors.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPTKmCiPD-T"
      },
      "source": [
        "s_ind = 0 # Plot the first time series\n",
        "t_ind = 100 # Plot the first 100 indices in the time series\n",
        "\n",
        "#Plot the x acceleration\n",
        "x_data = ds.acceleration_x[s_ind].numpy()[:t_ind]\n",
        "sampling_rate_x = ds.acceleration_x.info.sampling_rate_s\n",
        "\n",
        "plt.plot(np.arange(0, x_data.size)*sampling_rate_x, x_data, label='acceleration_x')\n",
        "\n",
        "#Plot the y acceleration\n",
        "y_data = ds.acceleration_y[s_ind].numpy()[:t_ind]\n",
        "sampling_rate_y = ds.acceleration_y.info.sampling_rate_s\n",
        "\n",
        "plt.plot(np.arange(0, y_data.size)*sampling_rate_y, y_data, label='acceleration_y')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('time [s]', fontweight = 'bold')\n",
        "plt.ylabel('acceleration [g]', fontweight = 'bold')\n",
        "plt.title('Weight: {} {}, Height: {} {}'.format(ds.subjects_info.weight[s_ind].numpy()[0],\n",
        "                                               ds.subjects_info.weight.info.units,\n",
        "                                               ds.subjects_info.height[s_ind].numpy()[0],\n",
        "                                               ds.subjects_info.height.info.units),\n",
        "         fontweight = 'bold')\n",
        "\n",
        "plt.xlim([0, 10])\n",
        "plt.grid()\n",
        "plt.gcf().set_size_inches(8, 5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79QnkE-UUySP"
      },
      "source": [
        "Congrats! You just converted a time-series dataset to Hub format! 🎉\n",
        "\n"
      ]
    }
  ]
}