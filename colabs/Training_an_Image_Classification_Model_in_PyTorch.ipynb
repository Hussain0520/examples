{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training an Image Classification Model in PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/activeloopai/examples/blob/main/colabs/Training_an_Image_Classification_Model_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKU8kmSs65xv"
      },
      "source": [
        "# ***Training an Image Classification Model in PyTorch***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zK9b4yiMRzB"
      },
      "source": [
        "#### The primary objective for Hub is to enable users to manage their data more easily so they can train better ML models. This tutorial shows you how to train a simple image classification model while streaming data from a Hub dataset stored in the cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UseHLcoRIYz"
      },
      "source": [
        "## Install Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mOffq5RN-T"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip3 install hub\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOkA83IsRWYo"
      },
      "source": [
        "# IMPORTANT - Please restart your Colab runtime after installing Hub!\n",
        "# This is a Colab-specific issue that prevents PIL from working properly.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wGo53ndMTCB"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52h9xKujOJFs"
      },
      "source": [
        "The first step is to select a dataset for training. This tutorial uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset that has already been converted into hub format. It is a simple image classification dataset that categorizes images by clothing type (trouser, shirt, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neD2jhKDQ5WD"
      },
      "source": [
        "import hub\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os, time\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "ds_train = hub.load('hub://activeloop/fashion-mnist-train')\n",
        "ds_test = hub.load('hub://activeloop/fashion-mnist-test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jtotSNzeJ0"
      },
      "source": [
        "Image.fromarray(ds_train.images[0].numpy()).resize((100,100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPSz9kml03Aa"
      },
      "source": [
        "print(ds_train.labels.info.class_names[str(ds_train.labels[0].numpy()[0])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np5fIbViHlCu"
      },
      "source": [
        "The next step is to define a transformation function that will process the data and convert it into a format that can be passed into a deep learning model. The syntax for the transformation function is that the input parameter is a sample from a Hub dataset in dictionary syntax, and the return value is a dictionary containing the data that the training loop uses to train the model. In this particular example, `torchvision.transforms` is used as a part of the transformation pipeline that performs operations such as normalization and image augmentation (rotation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqdWgumwQ1d6"
      },
      "source": [
        "def transform(sample_in):\n",
        "    return {'images': tform(sample_in['images']), 'labels': sample_in['labels']}\n",
        "\n",
        "tform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # Must convert to PIL image for subsequent operations to run\n",
        "    transforms.RandomRotation(20), # Image augmentation\n",
        "    transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToNQ3WwfIJZf"
      },
      "source": [
        "**Note:** Don't worry if the above syntax is a bit confusing ðŸ˜µ! We're currently improving it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGmWr44PIQMk"
      },
      "source": [
        "You are now ready to create a pytorch dataloader that connects the Hub dataset to the PyTorch model. This can be done using the provided method `ds.pytorch()` , which automatically applies the user-defined transformation function, takes care of random shuffling (if desired), and converts hub data to PyTorch tensors. The `num_workers` parameter can be used to parallelize data preprocessing, which is critical for ensuring that preprocessing does not bottleneck the overall training workflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeiU4LobROdE"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = ds_train.pytorch(num_workers = 2, shuffle = True, transform = transform, batch_size = batch_size)\n",
        "test_loader = ds_test.pytorch(num_workers = 2, transform = transform, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dco8HW9ROXS"
      },
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snt5b6qwIZQ_"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5LZrDU4I1GO"
      },
      "source": [
        "This tutorial uses a pre-trained [ResNet18](https://pytorch.org/hub/pytorch_vision_resnet/) neural network from the torchvision.models module, converted to a single-channel network for grayscale images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRBRaROLROUf"
      },
      "source": [
        "# Simple model can be trained on a CPU\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "net = models.resnet18(pretrained=True)\n",
        "# Convert model to grayscale\n",
        "net.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Update the fully connected layer based on the number of classes in the dataset\n",
        "net.fc = torch.nn.Linear(net.fc.in_features, len(ds_train.labels.info.class_names))\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "# Specity the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sVS5lTFI-gZ"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V65Xr8aBJCUL"
      },
      "source": [
        "Helper functions for training and testing the model are defined. Note that the dictionary that is returned by the transform function in the PyTorch dataloader is access here and is passed into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6cQJkHeJGtk"
      },
      "source": [
        "def train_model(loader, test_loader, model, epochs = 1):\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        # Zero the performance stats for each epoch\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        \n",
        "        for i, data in enumerate(loader):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs = data['images']\n",
        "            labels = torch.squeeze(data['labels'])\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "        \n",
        "            # Print performance statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 0:    # print every 10 batches\n",
        "                batch_time = time.time()\n",
        "                speed = (i+1)/(batch_time-start_time)\n",
        "                print('[%d, %5d] loss: %.3f, speed: %.2f, accuracy: %.2f %%' %\n",
        "                      (epoch + 1, i, running_loss, speed, accuracy))\n",
        "\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        print('Testing Model Performance')\n",
        "        test_model(test_loader, model)\n",
        "\n",
        "    print('Finished Training')\n",
        "    \n",
        "    \n",
        "def test_model(loader, model):\n",
        "    start_time = time.time()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(loader):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs = data['images']\n",
        "            labels = torch.squeeze(data['labels'])\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs.float())\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "        print('Finished Testing')\n",
        "        print('Testing accuracy: %.1f %%' %(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQWzFjzLJINu"
      },
      "source": [
        "The model and data are ready for training. Let's gooooooooooo ðŸš€!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMhm4VjDRf7i"
      },
      "source": [
        "train_model(train_loader, test_loader, net, epochs = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79QnkE-UUySP"
      },
      "source": [
        "Congrats! You successfully trained an image classification model while streaming data directly from the cloud! ðŸŽ‰"
      ]
    }
  ]
}
