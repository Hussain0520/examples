{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Processing Using Parallel Computing",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/activeloopai/examples/blob/main/colabs/Data_Processing_Using_Parallel_Computing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKU8kmSs65xv"
      },
      "source": [
        "# ***Data Processing Using Parallel Computing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zK9b4yiMRzB"
      },
      "source": [
        "#### [Step 7](https://docs.activeloop.ai/getting-started/parallel-computing) in the [Getting Started Guide](https://docs.activeloop.ai/getting-started) highlights how `hub.compute` can be used to rapidly upload datasets. This tutorial expands further and highlights the power of parallel computing for dataset processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UseHLcoRIYz"
      },
      "source": [
        "## Install Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5mOffq5RN-T"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip3 install hub\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOkA83IsRWYo"
      },
      "source": [
        "# IMPORTANT - Please restart your Colab runtime after installing Hub!\n",
        "# This is a Colab-specific issue that prevents PIL from working properly.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wGo53ndMTCB"
      },
      "source": [
        "## Dataset Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52h9xKujOJFs"
      },
      "source": [
        "Computer vision applications often require users to process and transform their data as part of their workflows. For example, you may perform perspective transforms, resize images, adjust their coloring, or many others. In this example, a flipped version of the MNIST dataset is created, which may be useful for training a model that identifies text from reflections in a mirror.\n",
        "\n",
        "The first step to creating a flipped version of the MNIST dataset is to define a function that will flip the dataset images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZtpnpTOp-5"
      },
      "source": [
        "import hub\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "@hub.compute\n",
        "def flip_horizontal(sample_in, sample_out):\n",
        "    ## First two arguments are always default arguments containing:\n",
        "    #     1st argument is an element of the input iterable (list, dataset, array,...)\n",
        "    #     2nd argument is a dataset sample\n",
        "    \n",
        "    # Append the label and image to the output sample\n",
        "    sample_out.labels.append(sample_in.labels.numpy())\n",
        "    sample_out.images.append(np.flip(sample_in.images.numpy(), axis = 1))\n",
        "    \n",
        "    return sample_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNMOv3LPOyAd"
      },
      "source": [
        "Next, the existing MNIST dataset is loaded, and `hub.like` is used to create an empty dataset with the same tensor structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCjN0EKwO1Pu"
      },
      "source": [
        "ds_mnist = hub.load('hub://activeloop/mnist-train')\n",
        "\n",
        "#We use the overwrite=True to make this code re-runnable\n",
        "ds_mnist_flipped = hub.like('./mnist_flipped', ds_mnist, overwrite = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4CPD4nmO3_S"
      },
      "source": [
        "Finally, the flipping operation is evaluated for the 1st 100 elements in the input dataset `ds_mnist`, and the result is automatically stored in `ds_mnist_flipped`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRIDfYXNO7kg"
      },
      "source": [
        "flip_horizontal().eval(ds_mnist[0:100], ds_mnist_flipped, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKvPUjxcUPvO"
      },
      "source": [
        "Let's check out the flipped images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2F4TXd0UEtH"
      },
      "source": [
        "Image.fromarray(ds_mnist.images[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3xsuWQTUEdm"
      },
      "source": [
        "Image.fromarray(ds_mnist_flipped.images[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCI61o-O9CV"
      },
      "source": [
        "##Dataset Processing Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXkD-gLgO_7L"
      },
      "source": [
        "In order to modularize your dataset processing, it is often helpful to create functions for specific data processing tasks, and combine them in pipelines in order to transform your data end-to-end. In this example, you can create a pipeline using the `flip_horizontal` function above and the `resize` function below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPTKmCiPD-T"
      },
      "source": [
        "@hub.compute\n",
        "def resize(sample_in, sample_out, new_size):\n",
        "    ## First two arguments are always default arguments containing:\n",
        "    #     1st argument is an element of the input iterable (list, dataset, array,...)\n",
        "    #     2nd argument is a dataset sample\n",
        "    ## Third argument is the required size for the output images\n",
        "    \n",
        "    # Append the label and image to the output sample\n",
        "    sample_out.labels.append(sample_in.labels.numpy())\n",
        "    sample_out.images.append(np.array(Image.fromarray(sample_in.images.numpy()).resize(new_size)))\n",
        "    \n",
        "    return sample_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDtcpMmuPFdg"
      },
      "source": [
        "Functions decorated using `hub.compute` can be easily combined into pipelines using hub.compose. Required arguments for the functions must be passed into the pipeline in this step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZMcRLeQPHq6"
      },
      "source": [
        "pipeline = hub.compose([flip_horizontal(), resize(new_size = (64,64))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg8rUpSWPJoK"
      },
      "source": [
        "Just like for the single-function example above, the input and output datasets are created first, and the pipeline is evaluated for the 1st 100 elements in the input dataset `ds_mnist_flipped`. The result is automatically stored in `ds_mnist_pipe`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnbEyjv2PL0a"
      },
      "source": [
        "#We use the overwrite=True to make this code re-runnable\n",
        "ds_mnist_pipe = hub.like('./mnist_pipeline', ds_mnist, overwrite = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4fkclYcPNjM"
      },
      "source": [
        "pipeline.eval(ds_mnist[0:100], ds_mnist_pipe, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79QnkE-UUySP"
      },
      "source": [
        "Let's check out the processed images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CrmZbCtUzMV"
      },
      "source": [
        "Image.fromarray(ds_mnist.images[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8itwG67U2g_"
      },
      "source": [
        "Image.fromarray(ds_mnist_pipe.images[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
